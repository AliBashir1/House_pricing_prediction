import numpy as np
import pandas as pd

from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline

from predict_house_median.CombinedAttributesAdder import CombinedAttributesAdder


def create_median_income_cat(
        housing_df: pd.DataFrame
) -> pd.DataFrame:
    # Median income plays an important role and it important give each income range a category
    # This is why stratified sampling is a proper way of sampling each category
    # categorized median_income
    housing_df["income_cat"] = np.ceil(housing_df["median_income"] / 1.5)
    return housing_df


def startified_shuffle(
        housing_df: pd.DataFrame
) -> tuple[pd.DataFrame, pd.DataFrame]:
    # Initialize variables to hold the stratified train and test sets
    # They will be assigned inside the loop and returned at the end
    strat_train_set = None
    strat_test_set = None

    # Stratified splitting using StratifiedShuffleSplit
    split = StratifiedShuffleSplit(
        n_splits=1,
        test_size=0.2,
        random_state=1
    )

    # Iterate over the indices generated by the split
    for train_index, test_index in split.split(housing_df, housing_df["income_cat"]):
        # Assign subsets of the DataFrame to train and test sets
        strat_train_set = housing_df.loc[train_index]
        strat_test_set = housing_df.loc[test_index]

    # Drop the 'income_cat' column from both train and test sets
    for set_ in (strat_train_set, strat_test_set):
        set_.drop("income_cat", axis=1, inplace=True)

    # Return the stratified train and test sets
    return strat_train_set, strat_test_set


def preprocessing_data(housing_tr: pd.DataFrame) -> pd.DataFrame:
    # Separate numerical and categorical attributes
    num_attribs = list(housing_tr.drop("ocean_proximity", axis=1))  # List of numerical attribute names
    cat_attribs = ["ocean_proximity"]  # list of a categorical attribute

    # Pipeline for numerical fields
    num_pipeline = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),  # Impute missing values with median
        ("attribs_added", CombinedAttributesAdder()),  # Add new features using CombinedAttributesAdder
        ("std_scaler", StandardScaler()),  # Scale numerical features using StandardScaler
    ])

    # Pipeline for both numerical and categorical fields
    full_pipeline = ColumnTransformer([
        ("num", num_pipeline, num_attribs),  # Apply num_pipeline to numerical attributes
        ("cat", OneHotEncoder(), cat_attribs)  # Apply OneHotEncoder to categorical attribute
    ])

    # Apply the full preprocessing pipeline to the housing_tr DataFrame
    housing_prepared = full_pipeline.fit_transform(housing_tr)

    return housing_prepared
